{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE noté -- Fondations statistiques du Machine Learning\n",
    "\n",
    "Cet devoir noté est composé de deux exercices. Il sera idéalement réalisé en binome et éventuellement seul. Les réponses seront données dans un notebook qui indiquera clairement les **noms et prénoms des élèves** l'ayant realisé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "\n",
    "Afin d'estimer efficacement le niveau de fatigue des ailes d'un d'avion au cours des années, il a été proposé de lancer une étude pour évaluer s'il était possible de déduire le niveau de stress subit par les ailes de l'avion lors de phases de vols diverses avec de données capteurs acquises en routine pendant les vols. Une personne ayant une expertise mécanique sur le modèle d'avion étudié a alors quantifié le niveau de stress subi par les ailes dans différentes phases de vols et différents contextes. Nous allons mettre en lien ces niveaux de stress avec des données capteurs acquises au même moment que les annotations. Nous allons pour cela utiliser la régression linaire. \n",
    "\n",
    "\n",
    "### QUESTION 1.1\n",
    "\n",
    "Les données d'apprentissage sont dans les fichiers *E1_sensor_vals.csv* et *E1_stress_vals.csv*. Ouvrez ces fichiers et mettez les données dans des numpy arrays ou des pandas dataframes *X* et *Y*. Représentez alors le lien entre les valeurs issues de chaque capteur et le niveau de stress dans des nuages de points 2D. Identifiez-vous des relations entre des données capteur et le niveau de stress ? Quels capteurs vous paraissent être les plus pertinents.\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Les *sensor_01*, *sensor_12* et *sensor_15* apparaissent comme les plus pertinents en termes de relations entre données capteur et niveau de stress : leur nuage de point semblent mettre en avant une relation linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Charger les données\n",
    "X = pd.read_csv('E1_sensor_vals.csv', sep=';')\n",
    "Y = pd.read_csv('E1_stress_vals.csv', sep=';')\n",
    "\n",
    "# Nombre de capteurs\n",
    "num_sensors = X.shape[1]\n",
    "\n",
    "# Créer des nuages de points pour chaque capteur\n",
    "for i in range(num_sensors):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X.iloc[:, i], Y, alpha=0.5)\n",
    "    plt.title(f'Relation entre le capteur {i+1} et le niveau de stress')\n",
    "    plt.xlabel(f'Valeurs du capteur {i+1}')\n",
    "    plt.ylabel('Niveau de stress')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### QUESTION 1.2\n",
    "On se demande s'il est possible de prédire le niveau de stress à partir d'**une seule** des variables *sensor_01*, *sensor_12* ou *sensor_15*.\n",
    "\n",
    "\n",
    "#### QUESTION 1.2.1\n",
    "\n",
    "Effectuez une régression linéaire simple entre chacune de ces trois variables et le niveau de stress. Quelle stratégie de validation croisée vous semble être la plus adaptée dans ce contexte ?\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "La stratégie des K-folds semble la plus pertinente dans notre contexte : elle est d'abord moins coûteuse en temps de calcul que la LOOCV, puis la taille des sous-échantillons est suffisamment faible pour éviter le surapprentissage.\n",
    "\n",
    "\n",
    "#### QUESTION 1.2.2\n",
    "\n",
    "Evaluez alors la qualité des prédictions en quantifiant les erreurs de prédiction au carré. Quelle variable vous semble être la plus pertinente pour prédire le niveau de stress et pourquoi ?\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "La $MSE$ (resp. le $R^2$) est minimale (resp. maximal) pour le *sensor_15*, ce qui laisse à penser que c'est la variable la plus pertinente pour prédire le niveau de stress.\n",
    "\n",
    "\n",
    "#### QUESTION 1.2.3\n",
    "\n",
    "Peut-on statistiquement affirmer qu'il existe une relation significative entre le niveau de stress et (indépendament) *sensor_01*, *sensor_12* ou bien *sensor_15* ? Si oui, décrivez votre procédure de test.\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Oui, en mesurant la p-value d'un test d'hypothèse H0 \"*Il n'existe pas de relation significative entre le niveau de stress et le capteur.*\" et d'hypothèse H1 \"*Il y a une relation significative entre ...*\" pour chacun des capteurs. Si celle-ci est inférieure à 0.05, alors on pourra rejeter H0 et ainsi affirmer qu'il y a bel et bien une relation significative entre le niveau de stress et le capteur en question. Pour cela, on ajuste le modèle de régression linéaire via OLS du module statsmodel et l'on en tire la p-value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.2.2\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sélectionner les capteurs 1, 12 et 15 (index 0, 11, 14 en Python)\n",
    "capteurs_indices = [0, 11, 14]  # Index des capteurs dans X\n",
    "\n",
    "for i in capteurs_indices:\n",
    "\n",
    "    # Sélectionner le capteur i\n",
    "    X_i = X.iloc[:, i].values.reshape(-1, 1)  # Reshape pour avoir la bonne forme (n_samples, n_features)\n",
    "    \n",
    "    # Créer le modèle de régression linéaire\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Effectuer une validation croisée (discutée ci-dessous)\n",
    "    scores = cross_val_score(model, X_i, Y, cv=5, scoring='neg_mean_squared_error')  # Validation croisée\n",
    "    mse_scores = -scores  # Inverser les scores pour obtenir les MSE\n",
    "    mean_mse = np.mean(mse_scores)  # Moyenne des MSE\n",
    "    \n",
    "    # Ajuster le modèle et faire des prédictions\n",
    "    model.fit(X_i, Y)\n",
    "    predictions = model.predict(X_i)\n",
    "    \n",
    "    # Calculer les métriques de performance\n",
    "    r2 = r2_score(Y, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(Y, predictions))\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    print(f\"Capteur {i + 1}:\")\n",
    "    print(f\"  MSE : {mean_mse:.2f}\")\n",
    "    print(f\"  R²: {r2:.2f}\")\n",
    "    print(f\"  RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Tracer les résultats\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(X_i, Y, alpha=0.5, label='Données réelles')\n",
    "    plt.plot(X_i, predictions, color='red', label='Régression linéaire', linewidth=2)\n",
    "    plt.title(f\"Capteur {i + 1} vs stress\")\n",
    "    plt.xlabel(f\"Capteur {i + 1} - valeurs\")\n",
    "    plt.ylabel(\"Niveau de stress\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### QUESTION 1.3\n",
    "\n",
    "On s'intéresse maintenant au lien entre la variable *sensor_12* et le niveau de stress. On peut remarquer qu'il semble exister une relation linéaire entre ces variables, mais que les données contiennent aussi deux valeurs aberrantes.\n",
    "\n",
    "\n",
    "#### QUESTION 1.3.1\n",
    "\n",
    "**Stratégie 1** : Définissez une première procédure pour détecter automatiquement les deux données aberrantes dans un jeu de données. On utilisera pour cela les distances de Cook.\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Voici notre procédure :\n",
    "- Nous ajustons un modèle de régression linéaire en utilisant la méthode des moindres carrés (OLS) pour modéliser la relation entre *sensor_12* et les niveaux de stress ;\n",
    "- Nous calculons les **distances de Cook**, qui renvoie les distances de Cook pour chaque observation dans le jeu de données ;\n",
    "- Nous définissons un **seuil** pour identifier les données aberrantes, en utilisant un seuil de **1**, une valeur couramment acceptée dans la littérature ;\n",
    "- Nous extrayons les indices des observations ayant des distances de Cook supérieures à ce seuil, indiquant qu'elles sont considérées comme des **points aberrants** ;\n",
    "- Nous créons un graphique en tige (stem plot) pour visualiser les distances de Cook de chaque observation, avec une ligne horizontale indiquant le seuil, afin de faciliter l'identification des observations aberrantes ;\n",
    "- Nous affichons les indices et les valeurs des observations identifiées comme aberrantes.\n",
    "\n",
    "\n",
    "#### QUESTION 1.3.2\n",
    "\n",
    "**Stratégie 2** : Nous allons ici utiliser toutes les observations pour l'apprentissage du modèle linéaire et sa validation. En supposant que les erreurs de prédiction suivent une loi normale centrée, pourrait-on aussi détecter les outliers à partir d'un test d'hypothèse. Si oui, décrivez la procédure.\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Voici notre procédure :\n",
    "- nous utilisons un **test de Shapiro-Wilk** avec la règle des 2-sigmas ;\n",
    "- nous calculons d'abord **les résidus**, puis effectuons le test de normalité avec Shapiro-Wilk qui permet de valider ou non l'hypothèse que les résidus suivent une distribution normale avec la p-valeur ;\n",
    "- nous calculons **la moyenne et l'écart-type des résidus** afin de définir les limites dans la règle des 2-sigmas ;\n",
    "Une fois les seuils définis par la règle des 2-sigmas, nous observons les valeurs en dehors de ces limites : il s'agit des outliers ; \n",
    "- nous affichons ensuite ces résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Question 1.3.1\n",
    "\n",
    "# Sélectionner sensor_12\n",
    "X_sensor_12 = sm.add_constant(X[['sensor_12']])  # Ajout d'une constante pour l'ordonnée à l'origine\n",
    "model_sensor_12 = sm.OLS(Y, X_sensor_12).fit()  # Ajustement du modèle\n",
    "\n",
    "# Calculer les distances de Cook\n",
    "influence = model_sensor_12.get_influence()\n",
    "cooks_d = influence.cooks_distance[0]\n",
    "\n",
    "# Identifier les points aberrants basés sur un seuil\n",
    "threshold = 1\n",
    "outliers_indices = np.where(cooks_d > threshold)[0] # Indices des outliers\n",
    "\n",
    "# Affichage des distances de Cook\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.stem(np.arange(len(cooks_d)), cooks_d, markerfmt=\",\", basefmt=\" \")\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Seuil')\n",
    "plt.title(\"Distances de Cook\")\n",
    "plt.xlabel(\"Indices des observations\")\n",
    "plt.ylabel(\"Distance de Cook\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Afficher les indices des valeurs aberrantes\n",
    "outliers_sensor_12 = X.loc[outliers_indices, ['sensor_12']]\n",
    "print(\"Indices des valeurs aberrantes (sensor_12):\", outliers_indices)\n",
    "print(\"Valeurs aberrantes :\")\n",
    "print(outliers_sensor_12)\n",
    "\n",
    "\n",
    "# Question 1.3.2\n",
    "\n",
    "# Calculer les résidus du modèle sensor_12\n",
    "residuals = model_sensor_12.resid\n",
    "\n",
    "# Effectuer le test de Shapiro-Wilk pour vérifier la normalité des résidus\n",
    "shapiro_stat, p_value = stats.shapiro(residuals)\n",
    "alpha = 0.05  # Seuil de signification\n",
    "if p_value < alpha:\n",
    "    print(\"Les résidus ne suivent pas une distribution normale (p-value < 0.05)\")\n",
    "else:\n",
    "    print(\"Les résidus suivent une distribution normale (p-value >= 0.05)\")\n",
    "\n",
    "# Calculer la moyenne et l'écart type des résidus\n",
    "mean_residual = np.mean(residuals)\n",
    "std_residual = np.std(residuals)\n",
    "\n",
    "# Définir les limites pour la règle des trois sigmas\n",
    "lower_limit = mean_residual - 2 * std_residual\n",
    "upper_limit = mean_residual + 2 * std_residual\n",
    "\n",
    "# Identifier les outliers basés sur la règle des trois sigmas\n",
    "outliers_indices = np.where((residuals < lower_limit) | (residuals > upper_limit))[0]\n",
    "\n",
    "# Afficher les résultats\n",
    "outliers_sensor_12 = X.loc[outliers_indices, ['sensor_12']]\n",
    "print(\"Indices des valeurs aberrantes (sensor_12):\", outliers_indices)\n",
    "print(\"Valeurs aberrantes :\")\n",
    "print(outliers_sensor_12)\n",
    "\n",
    "# Visualisation des résidus et des limites\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(residuals, 'o', label='Résidus')\n",
    "plt.axhline(y=lower_limit, color='red', linestyle='--', label='Limite inférieure (2 sigmas)')\n",
    "plt.axhline(y=upper_limit, color='green', linestyle='--', label='Limite supérieure (2 sigmas)')\n",
    "plt.title('Résidus du modèle sensor_12')\n",
    "plt.xlabel('Indices des observations')\n",
    "plt.ylabel('Résidus')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### QUESTION 1.4\n",
    "\n",
    "\n",
    "Nous supprimerons dans cette question les deux observations qui sont aberrantes sur la variable *sensor_12*.\n",
    "\n",
    "Nous souhaitons maintenant sélectionner automatiquement un nombre réduit, mais supérieur à 1, de capteurs qui nous permettraient de prédire au mieux le niveau de stress. Nous allons pour cela utiliser la régression multiple avec un terme de régularisation.\n",
    "\n",
    "#### QUESTION 1.4.1\n",
    "\n",
    "Quel traitement préalable allez-vous effectuer sur les données capteur et pourquoi ?\n",
    "\n",
    "## **Réponse :**\n",
    " \n",
    "Avant d'appliquer la régression multiple avec un terme de régularisation, il est important de réaliser certains traitements préalables sur les données des capteurs :\n",
    "1. **Suppression des valeurs aberrantes**, qui peuvent fausser l'ajustement du modèle et affecter la qualité des prédictions.\n",
    "2. **Vérification de la présence de valeurs manquantes dans les données**. Selon la quantité de données manquantes, vous pouvez choisir de les supprimer ou de les imputer avec des méthodes appropriées (comme la moyenne, la médiane ou des techniques plus avancées comme l'imputation par régression).\n",
    "3. **Normalisation des données**, pour replacer toutes les données à la même échelle.\n",
    "\n",
    "#### QUESTION 1.4.2\n",
    "\n",
    "Décrivez votre démarche de sélection de variables et vos résultats. Est-ce que l'utilisation des données capteurs vous semble fiable ?\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Voici notre démarche de sélection de variables :\n",
    "\n",
    "1. Après avoir supprimé les valeurs aberrantes de la variable *sensor_12*, on vérifie et gère les valeurs manquantes et normalise les données des capteurs.\n",
    "2. On effectue une analyse de corrélation entre les capteurs et le niveau de stress pour identifier les capteurs qui montrent une relation significative. Cela peut être fait en utilisant des matrices de corrélation.\n",
    "3. On utilise des méthodes de régression avec régularisation (ici Lasso) pour sélectionner les variables les plus pertinentes. Ces méthodes aident à réduire le surajustement en pénalisant les coefficients des variables non pertinentes.\n",
    "4. On met en œuvre une validation croisée pour évaluer la performance du modèle et s'assurer que la sélection des variables n'était pas due au hasard. Cela aide à évaluer la robustesse des variables sélectionnées.\n",
    "5. On mesure la performance du modèle à l'aide de la $MSE$ et du $R^2$ pour déterminer la qualité des prédictions.\n",
    "\n",
    "### **Analyse des résultats :**\n",
    "\n",
    "La régression Lasso par validation croisée sur les données données d'entrainement sélectionnent 2 capteurs (*sensor_12* et *sensor_15*) pour prédire les niveaux de stress (ie dont les coefficients $β$ sont non nuls). Ensuite, le graphe représentant les coefficients $β$ de la régression Lasso sur l'ensemble des données fait ressortir 4 capteurs au total (dont *sensor_12* et *sensor_15* pour lesquels les $β$ sont significativement plus grands). La différence dans le nombre de capteurs mis en avant s'explique ainsi : lors de l'entraînement initial avec validation croisée, différentes valeurs de régularisation $α$ sont testées pour trouver celle qui minimise l'erreur. Ensuite, lors du fit final sur l'ensemble complet des données, la valeur optimale de $α$ est utilisée. Cependant, les coefficients peuvent légèrement changer, et même si seulement deux capteurs étaient sélectionnés initialement, d'autres capteurs peuvent obtenir des coefficients non nuls lors du réajustement sur toutes les données. Cela est dû à l'augmentation de la quantité de données utilisée.\n",
    "\n",
    "### **Conclusion :**\n",
    "\n",
    "Au des coefficients de Lasso, nous estimons que l'utilisation de *sensor_12* et *sensor_15* est pertinente pour prédire les niveaux de stress sur l'aile d'avion.\n",
    "\n",
    "\n",
    "#### QUESTION 1.4.3\n",
    "\n",
    "Quelle démarche auriez-vous pour rendre compte des résultats de cette étude sachant que les données contenaient tout de même deux outliers ?\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "Malgré la présence d'outliers, nous pouvons interpréter les résultats en précisant que deux outliers ont été détectés et supprimés pour améliorer les prédictions faites par le modèle. Ici, nous avons même établi deux stratégies pour valider l'identification des outliers. \n",
    "Nous pouvons comparer les performances des modèles avec et sans les outliers (en regardant la MSE et R²). \n",
    "\n",
    "Enfin, nous aurions pu utiliser la régression par moindres carrés pondérés à la place des moindres carrés ordinaires qui est moins sensible aux outliers. La régression est plus robuste car des poids plus faibles sont appliqués aux valeurs aberrantes qui ont été déterminées par une analyse préliminaire des résidus du modèles OLS. Ainsi, l'utilisation de ces poids réduisent l'impact des valeurs aberrantes sur les estimations des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.4.2\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger les données des capteurs et des niveaux de stress\n",
    "data = pd.read_csv('E1_sensor_vals.csv', sep=';')\n",
    "Y = pd.read_csv('E1_stress_vals.csv', sep=';')\n",
    "\n",
    "# Suppression des valeurs aberrantes\n",
    "aberrant_indexes = [2, 62]  # Indices identifiés précédemment\n",
    "data = data.drop(index=aberrant_indexes)\n",
    "Y = Y.drop(index=aberrant_indexes)\n",
    "\n",
    "# Gestion des valeurs manquantes\n",
    "data = data.dropna()  # Suppression des lignes avec valeurs manquantes\n",
    "\n",
    "# Normalisation des données (sur les capteurs)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(data.drop(columns=data.columns[-1]))  # Ne pas inclure la colonne Stress\n",
    "\n",
    "# Séparation des données\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Régression Lasso avec validation croisée\n",
    "lasso = LassoCV(cv=5)  # Utilisation de 5-fold cross-validation\n",
    "lasso.fit(X_train, Y_train)\n",
    "\n",
    "# Sélection des variables\n",
    "selected_features = np.where(lasso.coef_ != 0)[0]\n",
    "print(f\"Capteurs sélectionnés : {data.columns[:-1][selected_features].tolist()}\")\n",
    "\n",
    "# Évaluation du modèle\n",
    "mse = cross_val_score(lasso, X_train, Y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "print(f\"MSE (validation croisée) : {-np.mean(mse):.3f}\")\n",
    "\n",
    "# Ajustement final sur l'ensemble d'apprentissage\n",
    "lasso.fit(X_scaled, Y)\n",
    "\n",
    "# Performance sur l'ensemble de test\n",
    "test_mse = mean_squared_error(Y_test, lasso.predict(X_test))\n",
    "print(f\"MSE sur l'ensemble de test : {test_mse:.3f}\")\n",
    "\n",
    "# Affichage des coefficients du modèle\n",
    "coefficients = pd.Series(lasso.coef_, index=data.columns[:-1])\n",
    "plt.figure(figsize=(10, 6))\n",
    "coefficients.plot(kind='bar')\n",
    "plt.title('Coefficients de la régression Lasso')\n",
    "plt.xlabel('Capteurs')\n",
    "plt.ylabel('Coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.4.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2\n",
    "\n",
    "Nous souhaitons évaluer si un nouveau produit a un effet significatif sur le rendement de moteurs. Pour y répondre, ce rendement (*Efficiency*) a été mesuré sur deux types de moteurs (*Brand_1* et *Brand_2*) et en testant différents niveaux de concentration (*Concentration*) du produit. Les observations sont dans le fichier *E2_Efficiency_Obs.csv*. A l'aide de modèles de régression linéaire et de tests statistiques, nous allons alors évaluer :\n",
    "- Le produit semble-t-il avoir un effet ?\n",
    "- Cet effet est-il différent en fonction de la marque du moteur ?\n",
    "- Cet effet dépend-il de la concentration du produit ?\n",
    "\n",
    "Afin de résoudre le problème, deux hypothèses seront effectuées :\n",
    "- Pour chaque marque de moteur, la relation entre la concentration et le rendement est supposée linéaire.\n",
    "- La distribution des erreurs de ce modèle est supposée suivre une loi Normale centrée.\n",
    "\n",
    "\n",
    "La démarche pour répondre à ces questions sera commentée dans le notebook rendu, quels qu'en soient ses résultats.\n",
    "\n",
    "\n",
    "Conseil : Avant de définir une stratégie de résolution, il est recommandé de visualiser les données de *E2_Efficiency_Obs.csv* en distinguant bien les observations obtenues dans les groupes *Brand_1* et *Brand_2*.\n",
    "\n",
    "\n",
    "## **Réponse :**\n",
    "\n",
    "### 1. **Le produit semble-t-il avoir un effet ?**\n",
    "\n",
    "A l'affichage des données, il semble en effet y avoir un effet significatif sur le rendement des moteurs. Après régression linéaire effectuée entre le produit et *Brand_1* et *Brand_2*, on obtient les informations suivantes :\n",
    "- Pour *Brand_1*, la concentration du produit a un effet hautement significatif sur l'efficacité, avec un coefficient de 0.4915 et une p-valeur proche de 0 (p < 0.001). Cela montre qu'une augmentation de la concentration entraîne une augmentation significative du rendement ;\n",
    "- Pour *Brand_2*, le coefficient de la concentration est de **0.3090** avec une p-valeur de **0.000**. Cela confirme également que le produit a un effet significatif sur le rendement des moteurs de cette marque. En effet, une augmentation de la concentration de 1 unité est associée à une augmentation de l'efficacité de **0.3090**.\n",
    "\n",
    "### 2. **Cet effet est-il différent en fonction de la marque du moteur ?**\n",
    "\n",
    "Oui, l'effet du produit semble dépendre de la marque du moteur.\n",
    "- Le modèle avec interaction entre la **concentration** et la **marque** permet d'évaluer si cet effet est différent selon les marques. Si le terme d'interaction (`Concentration:Brand_binary`) est significatif, cela indiquerait que l'effet de la concentration sur l'efficacité est différent pour *Brand_1* et *Brand_2*. Les résultats du modèle d'interaction (résumé à compléter) devraient montrer si cet effet est statistiquement différent entre les deux marques. Il est pertinent de comparer les coefficients des deux marques : *Brand_1* (0.4915) semble avoir un effet plus fort que *Brand_2* (0.3090), ce qui pourrait suggérer des différences dans la manière dont chaque marque réagit à la concentration du produit.\n",
    "\n",
    "### 3. **Cet effet dépend-il de la concentration du produit ?**\n",
    "\n",
    "Oui, l'effet du produit dépend directement de la concentration, comme montré par les régressions.\n",
    "- Pour *Brand_1*, la relation entre la concentration et l'efficacité est linéaire et positive, ce qui signifie que plus la concentration du produit augmente, plus le rendement du moteur augmente de manière prévisible.\n",
    "- Pour *Brand_2*, la relation est également positive, mais avec un coefficient inférieur. Cela pourrait indiquer que bien que l'efficacité augmente avec la concentration, l'ampleur de l'effet est plus faible comparée à *Brand_1*. Si le terme d'interaction est significatif, cela pourrait également suggérer que la dépendance à la concentration est différente pour *Brand_2*, indiquant une interaction entre la concentration et la marque.\n",
    "\n",
    "### Conclusion :\n",
    "Le produit a un effet significatif sur l'efficacité des moteurs, comme en témoigne les coefficients positifs pour les deux marques. Cependant, cet effet varie en fonction de la marque, avec une influence plus forte observée pour *Brand_1*. Cela justifie un ajustement des stratégies d'utilisation du produit en fonction du type de moteur, en tenant compte que *Brand_2* pourrait bénéficier davantage d'augmentations de concentration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Charger les données depuis le fichier CSV\n",
    "data = pd.read_csv('E2_Efficiency_Obs.csv')\n",
    "\n",
    "# Visualisation des données : Nuages de points pour chaque marque\n",
    "sns.lmplot(x='Concentration', y='Efficiency', hue='Brand', data=data, aspect=1.5, ci=None)\n",
    "plt.title('Relation entre la concentration et l\\'efficacité selon la marque')\n",
    "plt.show()\n",
    "\n",
    "# Séparer les données par marque\n",
    "brand_1_data = data[data['Brand'] == 'Brand_1']\n",
    "brand_2_data = data[data['Brand'] == 'Brand_2']\n",
    "\n",
    "\"\"\"\n",
    "# Ajuster le modèle pour Brand_1\n",
    "model_brand_1 = ols('Efficiency ~ Concentration', data=brand_1_data).fit()\n",
    "print(\"Régression pour Brand_1 :\")\n",
    "print(model_brand_1.summary())\n",
    "\"\"\"\n",
    "\n",
    "# Ajuster le modèle pour Brand_2\n",
    "model_brand_2 = ols('Efficiency ~ Concentration', data=brand_2_data).fit()\n",
    "print(\"\\nRégression pour Brand_2 :\")\n",
    "print(model_brand_2.summary())\n",
    "\n",
    "# Ajouter une variable binaire pour la marque (Brand_2 = 1, Brand_1 = 0)\n",
    "data['Brand_binary'] = data['Brand'].apply(lambda x: 1 if x == 'Brand_2' else 0)\n",
    "\n",
    "# Ajuster le modèle avec interaction entre marque et concentration\n",
    "interaction_model = ols('Efficiency ~ Concentration * Brand_binary', data=data).fit()\n",
    "\n",
    "# Résumé du modèle avec interaction\n",
    "print(\"\\nModèle avec interaction entre la concentration et la marque :\")\n",
    "print(interaction_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
